{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T17:00:38.727567Z",
     "iopub.status.busy": "2021-10-26T17:00:38.727285Z",
     "iopub.status.idle": "2021-10-26T17:00:38.730682Z",
     "shell.execute_reply": "2021-10-26T17:00:38.730051Z",
     "shell.execute_reply.started": "2021-10-26T17:00:38.727541Z"
    }
   },
   "source": [
    "# arXiv Paper Embedding\n",
    "\n",
    "\n",
    "## Multi GPU w/ Dask + CUDF\n",
    "Using Dask and CuDF to orchestrate sentence embedding over multiple GPU workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rapids and Dask Logos](https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/rapids_dask.png \"doc-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Imports\n",
    "\n",
    "* [`dask_saturn`](https://github.com/saturncloud/dask-saturn) and [`dask_distributed`](http://distributed.dask.org/en/stable/): Set up and run the Dask cluster in Saturn Cloud.\n",
    "* [`dask-cudf`](https://docs.rapids.ai/api/cudf/stable/basics/dask-cudf.html): Create distributed `cudf` dataframes using Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:04:01.495617Z",
     "iopub.status.busy": "2022-11-03T10:04:01.495159Z",
     "iopub.status.idle": "2022-11-03T10:04:06.870595Z",
     "shell.execute_reply": "2022-11-03T10:04:06.869859Z",
     "shell.execute_reply.started": "2022-11-03T10:04:01.495547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client, wait, get_worker\n",
    "\n",
    "from askyves.embedder import clean_description\n",
    "\n",
    "\n",
    "DATA_PATH = \"data/arxiv-metadata-oai-snapshot.json\"\n",
    "YEAR_CUTOFF = 2022\n",
    "YEAR_PATTERN = r\"(19|20[0-9]{2})\"\n",
    "\n",
    "PICKLED_DF_PATH = \"data/cdf.pkl\"\n",
    "MODEL_NAME = \"all-mpnet-base-v2\"\n",
    "OUTPUT_EMBEDDINGS_PATH = \"data/arxiv_embedings.pkl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start the Dask Cluster\n",
    "\n",
    "The template resource you are running has a Dask cluster already attached to it with three workers. The `dask-saturn` code below creates two important objects: a cluster and a client.\n",
    "\n",
    "* `cluster`: knows about and manages the scheduler and workers\n",
    "    - can be used to create, resize, reconfigure, or destroy those resources\n",
    "    - knows how to communicate with the scheduler, and where to find logs and diagnostic dashboards\n",
    "* `client`: tells the cluster to do things\n",
    "    - can send work to the cluster\n",
    "    - can restart all the worker processes\n",
    "    - can send data to the cluster or pull data back from the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:14:58.571178Z",
     "iopub.status.busy": "2022-11-03T10:14:58.570783Z",
     "iopub.status.idle": "2022-11-03T10:14:59.171925Z",
     "shell.execute_reply": "2022-11-03T10:14:59.171198Z",
     "shell.execute_reply.started": "2022-11-03T10:14:58.571153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_workers = 4\n",
    "cluster = SaturnCluster(n_workers=n_workers)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already started the Dask cluster on the resource page, then the code above will run much more quickly since it will not have to wait for the cluster to turn on.\n",
    "\n",
    ">**Pro tip**: Create and start the cluster in the Saturn Cloud UI before opening JupyterLab if you want to get a head start!\n",
    "\n",
    "The last command ensures the kernel waits until all the desired workers are online before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:15:02.451455Z",
     "iopub.status.busy": "2022-11-03T10:15:02.451048Z",
     "iopub.status.idle": "2022-11-03T10:15:02.456357Z",
     "shell.execute_reply": "2022-11-03T10:15:02.455503Z",
     "shell.execute_reply.started": "2022-11-03T10:15:02.451427Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.wait_for_workers(n_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:05:32.923568Z",
     "iopub.status.busy": "2022-11-03T10:05:32.923150Z",
     "iopub.status.idle": "2022-11-03T10:05:32.930186Z",
     "shell.execute_reply": "2022-11-03T10:05:32.929411Z",
     "shell.execute_reply.started": "2022-11-03T10:05:32.923542Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process(paper: dict):\n",
    "    paper = json.loads(paper)\n",
    "    if paper['journal-ref']:\n",
    "        years = [int(year) for year in re.findall(YEAR_PATTERN, paper['journal-ref'])]\n",
    "        years = [year for year in years if (year <= 2022 and year >= 1991)]\n",
    "        year = min(years) if years else None\n",
    "    else:\n",
    "        year = None\n",
    "    return {\n",
    "        'id': paper['id'],\n",
    "        'title': paper['title'],\n",
    "        'year': year,\n",
    "        'authors': paper['authors'],\n",
    "        'categories': ','.join(paper['categories'].split(' ')),\n",
    "        'abstract': paper['abstract'],\n",
    "        'update_date': paper[\"update_date\"],\n",
    "        \"doi\": paper[\"doi\"],\n",
    "        \"journal-ref\": paper[\"journal-ref\"],\n",
    "        \"submitter\": paper[\"submitter\"],\n",
    "        'input': clean_description(paper['title'] + ' ' + paper['abstract'])\n",
    "    }\n",
    "\n",
    "def papers():\n",
    "    with open(DATA_PATH, 'r') as f:\n",
    "        for paper in f:\n",
    "            paper = process(paper)\n",
    "            if paper['year']:\n",
    "                yield paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:09:39.949325Z",
     "iopub.status.busy": "2022-11-03T10:09:39.948949Z",
     "iopub.status.idle": "2022-11-03T10:09:39.952888Z",
     "shell.execute_reply": "2022-11-03T10:09:39.952005Z",
     "shell.execute_reply.started": "2022-11-03T10:09:39.949298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf = cudf.DataFrame(list(papers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T11:06:34.686107Z",
     "iopub.status.busy": "2022-10-30T11:06:34.685699Z",
     "iopub.status.idle": "2022-10-30T11:06:37.938907Z",
     "shell.execute_reply": "2022-10-30T11:06:37.938245Z",
     "shell.execute_reply.started": "2022-10-30T11:06:34.686080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pro Tip: Pickle the dataframe\n",
    "# This might save you time in the future so you don't have to do all of that again\n",
    "with open(PICKLED_DF_PATH, 'wb') as f:\n",
    "    pickle.dump(cdf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:15:14.751569Z",
     "iopub.status.busy": "2022-11-03T10:15:14.751170Z",
     "iopub.status.idle": "2022-11-03T10:15:15.771983Z",
     "shell.execute_reply": "2022-11-03T10:15:15.771332Z",
     "shell.execute_reply.started": "2022-11-03T10:15:14.751540Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pickle\n",
    "# with open(PICKLED_DF_PATH, 'rb') as f:\n",
    "#     cdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dask to parallelize things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:15:35.321865Z",
     "iopub.status.busy": "2022-11-03T10:15:35.321334Z",
     "iopub.status.idle": "2022-11-03T10:15:35.352444Z",
     "shell.execute_reply": "2022-11-03T10:15:35.351431Z",
     "shell.execute_reply.started": "2022-11-03T10:15:35.321835Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert our CuDF to a Dask-CuDF\n",
    "ddf = dask_cudf.from_cudf(cdf, npartitions=n_workers).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:15:49.091987Z",
     "iopub.status.busy": "2022-11-03T10:15:49.091583Z",
     "iopub.status.idle": "2022-11-03T10:15:49.098125Z",
     "shell.execute_reply": "2022-11-03T10:15:49.097429Z",
     "shell.execute_reply.started": "2022-11-03T10:15:49.091960Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embed_partition(df: dask_cudf.DataFrame, model_name: str=MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Create embeddings on single partition of DF (one dask worker)\n",
    "    \"\"\"\n",
    "    worker = get_worker()\n",
    "    if hasattr(worker, \"model\"):\n",
    "        model = worker.model\n",
    "    else:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        model = SentenceTransformer(\"sentence-transformers/{model_name}\")\n",
    "        worker.model = model\n",
    "\n",
    "    print(\"embedding input\", flush=True)\n",
    "        \n",
    "    # embed the input      \n",
    "    vectors = model.encode(\n",
    "        sentences = df.input.values_host,\n",
    "        normalize_embeddings = True,\n",
    "        show_progress_bar = True\n",
    "    )\n",
    "    \n",
    "    # Convert to cudf series and return\n",
    "    df['vector'] = cudf.Series(vectors.tolist(), index=df.index)\n",
    "    return df[['id', 'vector']]\n",
    "\n",
    "def clear_workers():\n",
    "    \"\"\"\n",
    "    Deletes model attribute, freeing up memory on the Dask workers\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import gc\n",
    "\n",
    "    worker = get_worker()\n",
    "    if hasattr(worker, \"model\"):\n",
    "        del worker.model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:15:51.983466Z",
     "iopub.status.busy": "2022-11-03T10:15:51.982985Z",
     "iopub.status.idle": "2022-11-03T11:07:53.588145Z",
     "shell.execute_reply": "2022-11-03T11:07:53.587317Z",
     "shell.execute_reply.started": "2022-11-03T10:15:51.983435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df = ddf[[\"id\", \"input\"]].map_partitions(\n",
    "    func = embed_partition,\n",
    "    meta = {\n",
    "      \"id\": object,\n",
    "      \"vector\": cudf.ListDtype('float32')\n",
    "    }\n",
    ")\n",
    "# Gather results\n",
    "output_df = output_df.persist()\n",
    "%time _ = wait(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T11:07:53.664513Z",
     "iopub.status.busy": "2022-11-03T11:07:53.664219Z",
     "iopub.status.idle": "2022-11-03T11:07:53.683790Z",
     "shell.execute_reply": "2022-11-03T11:07:53.682887Z",
     "shell.execute_reply.started": "2022-11-03T11:07:53.664491Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_ddf = ddf.merge(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T14:25:57.780170Z",
     "iopub.status.busy": "2022-11-03T14:25:57.779797Z",
     "iopub.status.idle": "2022-11-03T14:25:57.784025Z",
     "shell.execute_reply": "2022-11-03T14:25:57.783344Z",
     "shell.execute_reply.started": "2022-11-03T14:25:57.780139Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_cols = list(full_ddf.columns)\n",
    "str_cols.remove(\"vector\")\n",
    "full_ddf[str_cols] = full_ddf[str_cols].fillna('').astype(str)\n",
    "full_ddf = full_ddf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T11:08:21.732677Z",
     "iopub.status.busy": "2022-11-03T11:08:21.732367Z",
     "iopub.status.idle": "2022-11-03T11:09:59.503060Z",
     "shell.execute_reply": "2022-11-03T11:09:59.498851Z",
     "shell.execute_reply.started": "2022-11-03T11:08:21.732649Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(OUTPUT_EMBEDDINGS_PATH, 'wb') as f:\n",
    "    pickle.dump(full_ddf.compute().to_pandas(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T10:14:50.679479Z",
     "iopub.status.busy": "2022-11-03T10:14:50.678771Z",
     "iopub.status.idle": "2022-11-03T10:14:50.682621Z",
     "shell.execute_reply": "2022-11-03T10:14:50.681840Z",
     "shell.execute_reply.started": "2022-11-03T10:14:50.679447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleanup dask worker RAM\n",
    "client.run(clear_workers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env_redis_arxiv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c59ea6fdfc116911e26472a89da1e9112a5c644b926bc2cce80de33436f2384"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
